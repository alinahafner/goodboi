{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_training_with_DLC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "h2YUA4w57UTo",
        "58NzYUDx-W0C",
        "1NuJysSCCl9l",
        "NuFsPYxwVoZf",
        "v2gW6aDV-WML",
        "frYGVwUV2cE-",
        "DBf4xfIpZqex"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Package Installation"
      ],
      "metadata": {
        "id": "fl_YYDyi7PgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageai\n",
        "!pip install deeplabcut\n",
        "!pip install tensorflow-object-detection-api"
      ],
      "metadata": {
        "id": "x7lKimsj7u-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0f6f50d-09cf-42f6-ffe2-7ffba30128dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageai in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Collecting numpy==1.19.3\n",
            "  Using cached numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.1.2.30)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied: matplotlib==3.3.2 in /usr/local/lib/python3.7/dist-packages (from imageai) (3.3.2)\n",
            "Collecting keras==2.4.3\n",
            "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting pillow==7.0.0\n",
            "  Using cached Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Requirement already satisfied: keras-resnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2021.10.8)\n",
            "Installing collected packages: numpy, pillow, keras\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.0.1\n",
            "    Uninstalling Pillow-9.0.1:\n",
            "      Successfully uninstalled Pillow-9.0.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "deeplabcut 2.2.0.6 requires Pillow>=7.1, but you have pillow 7.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.4.3 numpy-1.19.3 pillow-7.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "keras",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deeplabcut in /usr/local/lib/python3.7/dist-packages (2.2.0.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.0.2)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.51.2)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.13.2)\n",
            "Collecting Pillow>=7.1\n",
            "  Using cached Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Requirement already satisfied: tables<=3.6.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.19.3)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.3.5)\n",
            "Requirement already satisfied: scikit-image<=0.18.1,>=0.17 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.18.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (4.62.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (3.3.2)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.4.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: tensorpack in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.11)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (5.5.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.17.21)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (0.2.3.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from deeplabcut) (2.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (1.8.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->deeplabcut) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->deeplabcut) (2018.9)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15.0->deeplabcut) (0.2.6)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<=0.18.1,>=0.17->deeplabcut) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<=0.18.1,>=0.17->deeplabcut) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib->deeplabcut) (2021.10.8)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11->deeplabcut) (0.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11->deeplabcut) (21.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables<=3.6.1->deeplabcut) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.43.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (13.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (3.3.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.10.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0->deeplabcut) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->deeplabcut) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.0->deeplabcut) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->deeplabcut) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->deeplabcut) (0.2.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->deeplabcut) (0.34.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->deeplabcut) (0.7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deeplabcut) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deeplabcut) (3.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (0.8.9)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.4.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (0.4.7.1)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (1.0.3)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (22.3.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack->deeplabcut) (5.4.8)\n",
            "Installing collected packages: Pillow, numpy, keras\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.3\n",
            "    Uninstalling numpy-1.19.3:\n",
            "      Successfully uninstalled numpy-1.19.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageai 2.1.6 requires keras==2.4.3, but you have keras 2.8.0 which is incompatible.\n",
            "imageai 2.1.6 requires numpy==1.19.3, but you have numpy 1.21.5 which is incompatible.\n",
            "imageai 2.1.6 requires pillow==7.0.0, but you have pillow 9.0.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.0.1 keras-2.8.0 numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "keras",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-object-detection-api in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.3.2)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.17.3)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.28)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (2.8.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.37.1)\n",
            "Requirement already satisfied: twine in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.7.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (9.0.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (1.21.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (2021.10.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tensorflow-object-detection-api) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.9.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (4.11.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->tensorflow-object-detection-api) (3.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (4.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.43.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.24.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (13.0.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.5.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->tensorflow-object-detection-api) (3.2.0)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (0.9.1)\n",
            "Requirement already satisfied: colorama>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (0.4.4)\n",
            "Requirement already satisfied: rfc3986>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (2.0.0)\n",
            "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.62.3)\n",
            "Requirement already satisfied: pkginfo>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (1.8.2)\n",
            "Requirement already satisfied: readme-renderer>=21.0 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (32.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (23.5.0)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine->tensorflow-object-detection-api) (3.3.1)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.17.1)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (36.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBb-CZWl6up0",
        "outputId": "ff98a04e-d935-4e31-817f-3dc83aba2888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "#base packages\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from imageai.Detection import ObjectDetection\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from operator import itemgetter\n",
        "import tqdm\n",
        "\n",
        "#training packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, MaxPool2D, Flatten, BatchNormalization, Activation, SeparableConv2D, MaxPooling2D, add, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "print(\"Tensorflow Version: \"+tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7AI8IFA7K6-",
        "outputId": "60eb8939-8d34-435c-8ac5-3ccf3f1b4da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "working_path = '/content/drive/MyDrive/Image data'\n",
        "os.chdir(working_path)"
      ],
      "metadata": {
        "id": "Vv9kU7JCjiCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "3e7da859-25dd-434f-9bea-ad638c045094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7da3e554b70d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mworking_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Image data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Image data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pathData = '/content/drive/MyDrive/Image data/training'\n",
        "newPath = '/content/drive/MyDrive/Image data/labeled-data'\n",
        "modelPath = '/content/drive/MyDrive/Image data/models/saved_models/resnet50_coco_best_v2.0.1.h5'\n",
        "padding = 0.1"
      ],
      "metadata": {
        "id": "h0a0SXE0jU67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Cleaning"
      ],
      "metadata": {
        "id": "h2YUA4w57UTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up dog detection model\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsRetinaNet()\n",
        "detector.setModelPath(modelPath)\n",
        "detector.loadModel()\n",
        "custom = detector.CustomObjects(dog=True)"
      ],
      "metadata": {
        "id": "bPErmYEx7dSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over all images\n",
        "for folder in os.listdir(pathData):\n",
        "    if folder != '.comments':\n",
        "        print('----------------------------------------')\n",
        "        print(folder + \":\")\n",
        "        path2 = pathData + '/' + folder     # path to emotion folder\n",
        "        counter = 1     # image counter\n",
        "        for filename in sorted(os.listdir(path2)):\n",
        "            if filename != '.comments':\n",
        "                pathImage = path2 + '/' + filename\n",
        "                list = filename.split('.')\n",
        "                pathNewImage = newPath + '/' + folder + str('{:03d}'.format(counter)) + '.jpg'\n",
        "                if not path.exists(pathNewImage):\n",
        "                    # detect dog\n",
        "                    dimage, detections = detector.detectCustomObjectsFromImage(custom_objects=custom, input_image=pathImage, output_type='array')\n",
        "\n",
        "                    if detections:\n",
        "                        image = cv2.imread(pathImage)\n",
        "                        height, width, channels = image.shape\n",
        "\n",
        "                        dog = (sorted(detections, key=lambda dog: dog['percentage_probability'], reverse=True))[0]\n",
        "                        x1 = max(0, int(round(dog['box_points'][0] * (1 - padding))))\n",
        "                        y1 = max(0, int(round(dog['box_points'][1] * (1 - padding))))\n",
        "                        x2 = min(width, int(round(dog['box_points'][2] * (1 + padding))))\n",
        "                        y2 = min(height, int(round(dog['box_points'][3] * (1 + padding))))\n",
        "\n",
        "                        image = image[y1:y2, x1:x2]\n",
        "                        if image.size:\n",
        "                            cv2.imwrite(pathNewImage, image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
        "                            print(pathImage + ' --> ' + pathNewImage)\n",
        "                            counter = counter + 1\n",
        "                        else: print('Empty Image!')\n",
        "                    else: print('No Dog: ' + pathImage)"
      ],
      "metadata": {
        "id": "Nz8qkNeT7gDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Posing"
      ],
      "metadata": {
        "id": "58NzYUDx-W0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deeplabcut.pose_estimation_tensorflow.config import load_config\n",
        "from deeplabcut.pose_estimation_tensorflow.core import predict\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tfc\n",
        "from object_detection.utils import label_map_util\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "u56TmpUu-aSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "metadata": {
        "id": "cd80qpUY_4x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourcePath = '/content/drive/MyDrive/Image data/labeled_data'\n",
        "targetPath = '/content/drive/MyDrive/Image data/keypoints'\n",
        "\n",
        "resizeWidth = 300                   # resize width for model prediction\n",
        "probability = 0.05\n",
        "\n",
        "probabilityAP = 0.005                # probability for keypoints only in animal pose data set\n",
        "animalPose = [20, 21, 22, 23]       # animal pose data set points\n",
        "\n",
        "probabilitySE = 0.05\n",
        "stanfordExtra = [13, 17, 18, 19]\n",
        "\n",
        "printNumbers = [0, 3, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19 ,22]     # keypoints to be displayed\n",
        "printNumbers = [22]     # keypoints to be displayed\n",
        "\n",
        "data = []\n",
        "bodyparts = ['L_F_Paw','L_F_Paw','L_F_Wrist','L_F_Wrist','L_F_Elbow','L_F_Elbow',\n",
        "\t\t 'L_B_Paw','L_B_Paw','L_B_Wrist','L_B_Wrist','L_B_Elbow','L_B_Elbow',\n",
        "\t\t 'R_F_Paw','R_F_Paw','R_F_Wrist','R_F_Wrist','R_F_Elbow','R_F_Elbow',\n",
        "\t\t 'R_B_Paw','R_B_Paw','R_B_Wrist','R_B_Wrist','R_B_Elbow','R_B_Elbow',\n",
        "\t\t 'Tailset','Tailset','Tailtip', 'Tailtip',\n",
        "\t\t 'L_Base_Ear','L_Base_Ear','R_Base_Ear','R_Base_Ear',\n",
        "\t\t 'Nose','Nose','Chin','Chin',\n",
        "\t\t 'L_Tip_Ear','L_Tip_Ear','R_Tip_Ear','R_Tip_Ear',\n",
        "\t\t 'L_Eye','L_Eye','R_Eye','R_Eye',\n",
        "\t\t 'Withers','Whithers','Throat','Throat']\n",
        "\n",
        "outputPath = '/content/drive/MyDrive/Image data/keypoints.csv'\n",
        "\n",
        "# test settings\n",
        "test = False\n",
        "testNumber = 20"
      ],
      "metadata": {
        "id": "Y_BwOGIk_8z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare DeepLabCut"
      ],
      "metadata": {
        "id": "1NuJysSCCl9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/drive/MyDrive/Image data/models/DogPoints-KF-2020-09-20/dlc-models/iteration-0/DogPointsSep20-trainset95shuffle1/test/pose_cfg.yaml"
      ],
      "metadata": {
        "id": "ji_RXuweGPKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_test_config = '/content/drive/MyDrive/Image data/models/DogPoints-KF-2020-09-20/dlc-models/iteration-0/DogPointsSep20-trainset95shuffle1/test/pose_cfg.yaml'\n",
        "dlc_cfg = load_config(str(path_test_config))\n",
        "sess, inputs, outputs = predict.setup_pose_prediction(dlc_cfg)      # sess, inputs, outputs"
      ],
      "metadata": {
        "id": "CwccUSzvAZWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare Images"
      ],
      "metadata": {
        "id": "NuFsPYxwVoZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow_heif"
      ],
      "metadata": {
        "id": "7nV4weOTuwlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from pillow_heif import register_heif_opener\n",
        "\n",
        "register_heif_opener()"
      ],
      "metadata": {
        "id": "vtazW9lBo-2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "working_path = '/content/drive/MyDrive/Image data'\n",
        "os.chdir(working_path)"
      ],
      "metadata": {
        "id": "9BuxmNjiaWJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "RiiqH9qEaqcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_path = working_path + '/training/'"
      ],
      "metadata": {
        "id": "bLi0aXV8a2Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "files = glob.glob(sourcePath + '/*')\n",
        "for f in files:\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "id": "v-oO03D-yl-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in os.listdir(start_path):\n",
        "  print(folder)\n",
        "  for count, f in enumerate(os.listdir(start_path + folder)):\n",
        "    num = count + 1\n",
        "    f_name, f_ext = os.path.splitext(f)\n",
        "    src_dir = start_path + folder\n",
        "    src_file = os.path.join(src_dir, f)\n",
        "    dst_file = os.path.join(sourcePath, f)\n",
        "    shutil.copy(src_file, sourcePath)\n",
        "    new_name = folder + '_' + str(num) + '.jpg'\n",
        "    new_file_name = os.path.join(sourcePath, new_name)\n",
        "    os.chdir(sourcePath)\n",
        "    os.rename(f, new_name)\n",
        "    im1 = Image.open(new_name)\n",
        "    im1 = im1.convert('RGB')\n",
        "    im1.save(new_name)\n",
        "    os.chdir(working_path)"
      ],
      "metadata": {
        "id": "lKNtrvGQbIDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Keypoints"
      ],
      "metadata": {
        "id": "v2gW6aDV-WML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('########################################################################')\n",
        "print('DeepLabCut Prediction')\n",
        "\n",
        "# deeplabcut detection\n",
        "testCounter = 0\n",
        "# probCounter = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0, 16:0, 17:0, 18:0, 19:0, 20:0, 21:0, 22:0, 23:0}\n",
        "for filename in sorted(os.listdir(sourcePath)):\n",
        "    if filename != '.DS_Store' and ((test and testCounter < testNumber) or test == False):\n",
        "        pathImage = sourcePath + '/' + filename\n",
        "        pathImageNew = targetPath + '/' + filename\n",
        "        print(pathImage + ' --> ' + pathImageNew)\n",
        "\n",
        "        # prepare image\n",
        "        image = imread(pathImage)  # read image\n",
        "        print(image.shape)\n",
        "        height = image.shape[0]\n",
        "        width = image.shape[1]\n",
        "        resizeHeight = int(round(height * resizeWidth / width))\n",
        "        image = resize(image, (resizeHeight, resizeWidth), anti_aliasing=False)\n",
        "        frame = img_as_ubyte(image)\n",
        "\n",
        "        # apply own DLC detector\n",
        "        pose = predict.getpose(frame, dlc_cfg, sess, inputs, outputs)  # detect keypoints\n",
        "        poseResized = []\n",
        "        scaleFactor = width / resizeWidth\n",
        "\n",
        "        image = cv2.imread(pathImage)\n",
        "        counterPoint = 0\n",
        "        coordinates = []\n",
        "        #coordinates.append(filename)\n",
        "        coordinates.append(pathImageNew)\n",
        "\n",
        "        # determine emotion\n",
        "        #if 'Anger' in filename:\n",
        "           # coordinates.append('anger')\n",
        "       # elif 'Fear' in filename:\n",
        "          #  coordinates.append('fear')\n",
        "       # elif 'Happiness' in filename:\n",
        "         #   coordinates.append('happiness')\n",
        "        #elif 'Relaxation' in filename:\n",
        "           # coordinates.append('relaxation')\n",
        "\n",
        "        for keypoint in pose:\n",
        "            good = False\n",
        "            # probCounter[counterPoint] = probCounter[counterPoint] + keypoint[2]\n",
        "            if counterPoint in animalPose and not keypoint[2] < probabilityAP:\n",
        "                good = True\n",
        "            elif counterPoint in stanfordExtra and not keypoint[2] < probabilitySE:\n",
        "                good = True\n",
        "            elif counterPoint not in animalPose and counterPoint not in stanfordExtra and not keypoint[2] < probability:\n",
        "                good = True\n",
        "\n",
        "            if good:\n",
        "                x = int(round(keypoint[0]*scaleFactor))\n",
        "                y = int(round(keypoint[1]*scaleFactor))\n",
        "                #cv2.circle(image, (x, y), 5, (0, 0, 255), -1)\n",
        "                cv2.putText(image, str(counterPoint), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
        "\n",
        "                coordinates.append(x)\n",
        "                coordinates.append(y)\n",
        "            else:\n",
        "                coordinates.append(-1)\n",
        "                coordinates.append(-1)\n",
        "\n",
        "            counterPoint += 1\n",
        "\n",
        "        cv2.imwrite(pathImageNew, image)\n",
        "        data.append(coordinates)\n",
        "        testCounter += 1\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(outputPath, index=False, header=None)"
      ],
      "metadata": {
        "id": "TWejU-XOCuLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sourcePath = '/content/drive/MyDrive/Image data/keypoints.csv'\n",
        "outputPath = '/content/drive/MyDrive/Image data/keypoints_scaled.csv'\n",
        "\n",
        "coordinates = pd.read_csv(sourcePath, header=None)\n",
        "\n",
        "#####################################################################\n",
        "#####################################################################\n",
        "\n",
        "\n",
        "# check if coordinate exists\n",
        "def coordinateNotNull(point):\n",
        "    if point == [-1,-1]: return False\n",
        "    return True\n",
        "\n",
        "# get the first filled coordinate of a list\n",
        "# None = no filled coordinate in list\n",
        "def getFilledCoordinate(pointList):\n",
        "    for point in pointList:\n",
        "        if coordinateNotNull(point): return point\n",
        "    return None\n",
        "\n",
        "# mirror image horizontally\n",
        "def mirrorImage(width, point):\n",
        "    if coordinateNotNull(point): return [width - point[0], point[1]]\n",
        "    else: return point\n",
        "\n",
        "# scale coordinate\n",
        "def scaleImage(width, height, point):\n",
        "    if coordinateNotNull(point): return [point[0]/width, point[1]/height]\n",
        "    else: return point\n",
        "\n",
        "#####################################################################\n",
        "#####################################################################\n",
        "\n",
        "data = []\n",
        "# iterate over images\n",
        "for row in range(0, len(coordinates.index)):\n",
        "    # create list for each dog keypoint\n",
        "    emotion = coordinates[0][row]\n",
        "    L_F_Paw = [coordinates[1][row], coordinates[2][row]]\n",
        "    L_F_Wrist = [coordinates[3][row], coordinates[4][row]]\n",
        "    L_F_Elbow = [coordinates[5][row], coordinates[6][row]]\n",
        "    L_B_Paw = [coordinates[7][row], coordinates[8][row]]\n",
        "    L_B_Wrist = [coordinates[9][row], coordinates[10][row]]\n",
        "    L_B_Elbow = [coordinates[11][row], coordinates[12][row]]\n",
        "    R_F_Paw = [coordinates[13][row], coordinates[14][row]]\n",
        "    R_F_Wrist = [coordinates[15][row], coordinates[16][row]]\n",
        "    R_F_Elbow = [coordinates[17][row], coordinates[18][row]]\n",
        "    R_B_Paw = [coordinates[19][row], coordinates[20][row]]\n",
        "    R_B_Wrist = [coordinates[21][row], coordinates[22][row]]\n",
        "    R_B_Elbow = [coordinates[23][row], coordinates[24][row]]\n",
        "    Tailset = [coordinates[25][row], coordinates[26][row]]\n",
        "    Tailtip = [coordinates[27][row], coordinates[28][row]]\n",
        "    L_Base_Ear = [coordinates[29][row], coordinates[30][row]]\n",
        "    R_Base_Ear = [coordinates[31][row], coordinates[32][row]]\n",
        "    Nose = [coordinates[33][row], coordinates[34][row]]\n",
        "    Chin = [coordinates[35][row], coordinates[36][row]]\n",
        "    L_Tip_Ear = [coordinates[37][row], coordinates[38][row]]\n",
        "    R_Tip_Ear = [coordinates[39][row], coordinates[40][row]]\n",
        "    L_Eye = [coordinates[41][row], coordinates[42][row]]\n",
        "    R_Eye = [coordinates[43][row], coordinates[44][row]]\n",
        "    Withers = [coordinates[45][row], coordinates[46][row]]\n",
        "    Throat = [coordinates[47][row], coordinates[48][row]]\n",
        "    #height = coordinates[49][row]\n",
        "    #width = coordinates[50][row]\n",
        "\n",
        "    # get a filled keypoint for the dog's back, front, up and down\n",
        "    back = getFilledCoordinate([Tailset, L_B_Paw, R_B_Paw])\n",
        "    front = getFilledCoordinate([Nose, Chin, L_Base_Ear, R_Base_Ear])\n",
        "    up = getFilledCoordinate([L_Base_Ear, R_Base_Ear, L_Eye, R_Eye, Nose, Chin])\n",
        "    down = getFilledCoordinate([L_F_Paw, R_F_Paw, L_B_Paw, R_F_Paw])\n",
        "\n",
        "    # determine direction the dog is standing\n",
        "    lookingLeft = None\n",
        "    if back is not None and front is not None:\n",
        "        if front[0] <= back[0]: lookingLeft = True\n",
        "        else: lookingLeft = False\n",
        "\n",
        "    # mirror image\n",
        "    if lookingLeft is False:\n",
        "        L_F_Paw = mirrorImage(width,L_F_Paw)\n",
        "        L_F_Wrist = mirrorImage(width,L_F_Wrist)\n",
        "        L_F_Elbow = mirrorImage(width,L_F_Elbow)\n",
        "        L_B_Paw = mirrorImage(width,L_B_Paw)\n",
        "        L_B_Wrist = mirrorImage(width,L_B_Wrist)\n",
        "        L_B_Elbow = mirrorImage(width,L_B_Elbow)\n",
        "        R_F_Paw = mirrorImage(width,R_F_Paw)\n",
        "        R_F_Wrist = mirrorImage(width,R_F_Wrist)\n",
        "        R_F_Elbow = mirrorImage(width,R_F_Elbow)\n",
        "        R_B_Paw = mirrorImage(width,R_B_Paw)\n",
        "        R_B_Wrist = mirrorImage(width,R_B_Wrist)\n",
        "        R_B_Elbow = mirrorImage(width,R_B_Elbow)\n",
        "        Tailset = mirrorImage(width, Tailset)\n",
        "        Tailtip = mirrorImage(width,Tailtip)\n",
        "        L_Base_Ear = mirrorImage(width,L_Base_Ear)\n",
        "        R_Base_Ear = mirrorImage(width,R_Base_Ear)\n",
        "        Nose = mirrorImage(width,Nose)\n",
        "        Chin = mirrorImage(width,Chin)\n",
        "        L_Tip_Ear = mirrorImage(width,L_Tip_Ear)\n",
        "        R_Tip_Ear = mirrorImage(width,R_Tip_Ear)\n",
        "        L_Eye = mirrorImage(width,L_Eye)\n",
        "        R_Eye = mirrorImage(width,R_Eye)\n",
        "        Withers = mirrorImage(width,Withers)\n",
        "        Throat = mirrorImage(width,Throat)\n",
        "\n",
        "    # scale image\n",
        "    L_F_Paw = scaleImage(width, height, L_F_Paw)\n",
        "    L_F_Wrist = scaleImage(width, height, L_F_Wrist)\n",
        "    L_F_Elbow = scaleImage(width, height, L_F_Elbow)\n",
        "    L_B_Paw = scaleImage(width, height, L_B_Paw)\n",
        "    L_B_Wrist = scaleImage(width, height, L_B_Wrist)\n",
        "    L_B_Elbow = scaleImage(width, height, L_B_Elbow)\n",
        "    R_F_Paw = scaleImage(width, height, R_F_Paw)\n",
        "    R_F_Wrist = scaleImage(width, height, R_F_Wrist)\n",
        "    R_F_Elbow = scaleImage(width, height, R_F_Elbow)\n",
        "    R_B_Paw = scaleImage(width, height, R_B_Paw)\n",
        "    R_B_Wrist = scaleImage(width, height, R_B_Wrist)\n",
        "    R_B_Elbow = scaleImage(width, height, R_B_Elbow)\n",
        "    Tailset = scaleImage(width, height, Tailset)\n",
        "    Tailtip = scaleImage(width, height, Tailtip)\n",
        "    L_Base_Ear = scaleImage(width, height, L_Base_Ear)\n",
        "    R_Base_Ear = scaleImage(width, height, R_Base_Ear)\n",
        "    Nose = scaleImage(width, height, Nose)\n",
        "    Chin = scaleImage(width, height, Chin)\n",
        "    L_Tip_Ear = scaleImage(width, height, L_Tip_Ear)\n",
        "    R_Tip_Ear = scaleImage(width, height, R_Tip_Ear)\n",
        "    L_Eye = scaleImage(width, height, L_Eye)\n",
        "    R_Eye = scaleImage(width, height, R_Eye)\n",
        "    Withers = scaleImage(width, height, Withers)\n",
        "    Throat = scaleImage(width, height, Throat)\n",
        "\n",
        "    data.append([emotion,\n",
        "                 L_F_Paw[0],\n",
        "                 L_F_Paw[1],\n",
        "                 L_F_Wrist[0],\n",
        "                 L_F_Wrist[1],\n",
        "                 L_F_Elbow[0],\n",
        "                 L_F_Elbow[1],\n",
        "                 L_B_Paw[0],\n",
        "                 L_B_Paw[1],\n",
        "                 L_B_Wrist[0],\n",
        "                 L_B_Wrist[1],\n",
        "                 L_B_Elbow[0],\n",
        "                 L_B_Elbow[1],\n",
        "                 R_F_Paw[0],\n",
        "                 R_F_Paw[1],\n",
        "                 R_F_Wrist[0],\n",
        "                 R_F_Wrist[1],\n",
        "                 R_F_Elbow[0],\n",
        "                 R_F_Elbow[1],\n",
        "                 R_B_Paw[0],\n",
        "                 R_B_Paw[1],\n",
        "                 R_B_Wrist[0],\n",
        "                 R_B_Wrist[1],\n",
        "                 R_B_Elbow[0],\n",
        "                 R_B_Elbow[1],\n",
        "                 Tailset[0],\n",
        "                 Tailset[1],\n",
        "                 Tailtip[0],\n",
        "                 Tailtip[1],\n",
        "                 L_Base_Ear[0],\n",
        "                 L_Base_Ear[1],\n",
        "                 R_Base_Ear[0],\n",
        "                 R_Base_Ear[1],\n",
        "                 Nose[0],\n",
        "                 Nose[1],\n",
        "                 Chin[0],\n",
        "                 Chin[1],\n",
        "                 L_Tip_Ear[0],\n",
        "                 L_Tip_Ear[1],\n",
        "                 R_Tip_Ear[0],\n",
        "                 R_Tip_Ear[1],\n",
        "                 L_Eye[0],\n",
        "                 L_Eye[1],\n",
        "                 R_Eye[0],\n",
        "                 R_Eye[1],\n",
        "                 Withers[0],\n",
        "                 Withers[1],\n",
        "                 Throat[0],\n",
        "                 Throat[1]])\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(outputPath, index=False, header=False)"
      ],
      "metadata": {
        "id": "SpD7weky1nIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pose Estimation"
      ],
      "metadata": {
        "id": "frYGVwUV2cE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sourcePath = '/content/drive/MyDrive/Image data/keypoints.csv'\n",
        "outputPath = '/content/drive/MyDrive/Image data/poses.csv'\n",
        "\n",
        "b_paw = 'get_fucked'\n",
        "b_elbow = 'arsehole'\n",
        "\n",
        "coordinates = pd.read_csv(sourcePath, header=None)\n",
        "\n",
        "test = False\n",
        "testNumber = 20\n",
        "\n",
        "data = []\n",
        "names = ['filepath',\n",
        "         'bodyWeight',\n",
        "         'tailPosition',\n",
        "         'headPosition',\n",
        "         'earPosition',\n",
        "         'mouthCondition',\n",
        "         'frontLeg',\n",
        "         'backLeg']\n",
        "\n",
        "#####################################################################\n",
        "#####################################################################\n",
        "\n",
        "# check if coordinate exists\n",
        "def coordinateNotNull(tuple):\n",
        "    if tuple == (-1,-1): return False\n",
        "    return True\n",
        "\n",
        "# get angle between 3 coordinates at coordinate b\n",
        "def getAngle(a, b, c):\n",
        "    ba = np.asarray(a)-np.asarray(b)\n",
        "    bc = np.asarray(c)-np.asarray(b)\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "# determine line equation with 2 coordinates\n",
        "def getLineEquation(p1,p2):\n",
        "    slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
        "    intercept = p1[1] - slope * p1[0]\n",
        "    return slope, intercept\n",
        "\n",
        "# calculate if point is above a line determined by 2 coordinates\n",
        "# (0 = point is on line)\n",
        "def isRaised(lineStart, lineEnd, point):\n",
        "    if lineStart[0] == lineEnd[0]: return 0\n",
        "    slope, intercept = getLineEquation(lineStart, lineEnd)\n",
        "    lineY = intercept + slope*point[0]\n",
        "    if lineY >= point[1]:\n",
        "        return 1\n",
        "    else: return -1\n",
        "\n",
        "# check if point is before checkpoint\n",
        "# before is determined by the direction the dog faces\n",
        "def isBefore(checkpoint, point, left):\n",
        "    if left:\n",
        "        if (checkpoint[0] <= point[0]): return True\n",
        "        else: return False\n",
        "    else:\n",
        "        if (checkpoint[0] >= point[0]): return True\n",
        "        else: return False\n",
        "\n",
        "# check if dog faces the camera frontal\n",
        "def isFrontal(back, front, up, down):\n",
        "    width = abs(back[0] - front[0])\n",
        "    height = abs(down[1] - up[1])\n",
        "    if height/width > 4:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# get intersection of 2 lines determined by two coordinates each\n",
        "# None = no intersection\n",
        "def getIntersection(line1p1, line1p2, line2p1, line2p2):\n",
        "    if line1p1[0] != line1p2[0] and line2p1[0] != line2p2[0]:\n",
        "        slope1, intercept1 = getLineEquation(line1p1, line1p2)\n",
        "        slope2, intercept2 = getLineEquation(line2p1, line2p2)\n",
        "    else: return None\n",
        "    if slope1 != slope2:\n",
        "        x = (intercept1 - intercept2) / (slope2 - slope1)\n",
        "        y = slope1 * x + intercept1\n",
        "        return (x,y)\n",
        "    return None\n",
        "\n",
        "# get the first filled coordinate of a list\n",
        "# None = no filled coordinate in list\n",
        "def getFilledCoordinate(pointList):\n",
        "    for point in pointList:\n",
        "        if coordinateNotNull(point): return point\n",
        "    return None\n",
        "\n",
        "#####################################################################\n",
        "#####################################################################\n",
        "\n",
        "if test:\n",
        "    imageNumber = testNumber\n",
        "else: imageNumber = len(coordinates.index)\n",
        "\n",
        "counter = 0\n",
        "# iterate over images\n",
        "for row in range(0,imageNumber):\n",
        "    counter += 1\n",
        "    newRow = []\n",
        "\n",
        "    ###########################################################\n",
        "    # create tuple for each dog keypoint\n",
        "    L_F_Paw = (coordinates[1][row], coordinates[2][row])\n",
        "    L_F_Wrist = (coordinates[3][row], coordinates[4][row])\n",
        "    L_F_Elbow = (coordinates[5][row], coordinates[6][row])\n",
        "    L_B_Paw = (coordinates[7][row], coordinates[8][row])\n",
        "    L_B_Wrist = (coordinates[9][row], coordinates[10][row])\n",
        "    L_B_Elbow = (coordinates[11][row], coordinates[12][row])\n",
        "    R_F_Paw = (coordinates[13][row], coordinates[14][row])\n",
        "    R_F_Wrist = (coordinates[15][row], coordinates[16][row])\n",
        "    R_F_Elbow = (coordinates[17][row], coordinates[18][row])\n",
        "    R_B_Paw = (coordinates[19][row], coordinates[20][row])\n",
        "    R_B_Wrist = (coordinates[21][row], coordinates[22][row])\n",
        "    R_B_Elbow = (coordinates[23][row], coordinates[24][row])\n",
        "    Tailset = (coordinates[25][row], coordinates[26][row])\n",
        "    Tailtip = (coordinates[27][row], coordinates[28][row])\n",
        "    L_Base_Ear = (coordinates[29][row], coordinates[30][row])\n",
        "    R_Base_Ear = (coordinates[31][row], coordinates[32][row])\n",
        "    Nose = (coordinates[33][row], coordinates[34][row])\n",
        "    Chin = (coordinates[35][row], coordinates[36][row])\n",
        "    L_Tip_Ear = (coordinates[37][row], coordinates[38][row])\n",
        "    R_Tip_Ear = (coordinates[39][row], coordinates[40][row])\n",
        "    L_Eye = (coordinates[41][row], coordinates[42][row])\n",
        "    R_Eye = (coordinates[43][row], coordinates[44][row])\n",
        "    Withers = (coordinates[45][row], coordinates[46][row])\n",
        "    Throat = (coordinates[47][row], coordinates[48][row])\n",
        "\n",
        "    # get a filled keypoint for the dog's back, front, up and down\n",
        "    back = getFilledCoordinate([Tailset, L_B_Paw, R_B_Paw])\n",
        "    front = getFilledCoordinate([Nose, Chin, L_Base_Ear, R_Base_Ear])\n",
        "    up = getFilledCoordinate([L_Base_Ear, R_Base_Ear, L_Eye, R_Eye, Nose, Chin])\n",
        "    down = getFilledCoordinate([L_F_Paw, R_F_Paw, L_B_Paw, R_F_Paw])\n",
        "\n",
        "    # determine existing neck point\n",
        "    if coordinateNotNull(Withers): neck = Withers\n",
        "    elif coordinateNotNull(Throat): neck = Throat\n",
        "    else: neck = (-1, -1)\n",
        "\n",
        "    # determine if dog is standing frontal\n",
        "    frontal = False\n",
        "    if back is not None and front is not None and up is not None and down is not None:\n",
        "        frontal = isFrontal(back, front, up, down)\n",
        "\n",
        "    # determine direction the dog is standing\n",
        "    lookingLeft = None\n",
        "    if back is not None and front is not None:\n",
        "        if front[0] <= back[0]: lookingLeft = True\n",
        "        else: lookingLeft = False\n",
        "\n",
        "    # determine existing ear coordinates\n",
        "    base_ear, tip_ear = (-1,-1), (-1,-1)\n",
        "    if lookingLeft:\n",
        "        if (coordinateNotNull(L_Base_Ear) and coordinateNotNull(L_Tip_Ear)): base_ear, tip_ear = L_Base_Ear, L_Tip_Ear\n",
        "        elif (coordinateNotNull(R_Base_Ear) and coordinateNotNull(R_Tip_Ear)): base_ear, tip_ear = R_Base_Ear, R_Tip_Ear\n",
        "    else:\n",
        "        if (coordinateNotNull(R_Base_Ear) and coordinateNotNull(R_Tip_Ear)): base_ear, tip_ear = R_Base_Ear, R_Tip_Ear\n",
        "        elif (coordinateNotNull(L_Base_Ear) and coordinateNotNull(L_Tip_Ear)): base_ear, tip_ear = L_Base_Ear, L_Tip_Ear\n",
        "\n",
        "    ###########################################################\n",
        "    # emotion\n",
        "    newRow.append(coordinates[0][row])\n",
        "    # emotion = coordinates[0][row]\n",
        "    # if 'anger' in emotion: newRow.append(1)\n",
        "    # else: newRow.append(0)\n",
        "    # if 'fear' in emotion: newRow.append(1)\n",
        "    # else: newRow.append(0)\n",
        "    # if 'happiness' in emotion: newRow.append(1)\n",
        "    # else: newRow.append(0)\n",
        "    # if 'relaxation' in emotion: newRow.append(1)\n",
        "    # else: newRow.append(0)\n",
        "\n",
        "    # __________________________________________________________\n",
        "    # calculate bodyweight distribution\n",
        "    if coordinateNotNull(Tailset) \\\n",
        "        and coordinateNotNull(neck) \\\n",
        "        and lookingLeft is not None and not frontal \\\n",
        "        and ((coordinateNotNull(L_F_Paw) and coordinateNotNull(L_B_Paw))\n",
        "             or (coordinateNotNull(R_F_Paw) and coordinateNotNull(R_B_Paw))):\n",
        "\n",
        "        # determine existing paw pair\n",
        "        if coordinateNotNull(L_F_Paw) and coordinateNotNull(L_B_Paw): paw1, paw2 = L_F_Paw, L_B_Paw\n",
        "        else: paw1, paw2 = R_F_Paw, R_B_Paw\n",
        "        intersection = getIntersection(paw1, paw2, neck, Tailset)\n",
        "        if intersection is None: bodyweight = 0\n",
        "        else:\n",
        "            bodyweight = getAngle(neck, intersection, paw1)\n",
        "            if isBefore(neck, intersection, lookingLeft): bodyweight = bodyweight*-1\n",
        "            if neck == Throat: bodyweight = -14.1 + 0.35 * bodyweight\n",
        "            newRow.append(bodyweight)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # tail position\n",
        "    if coordinateNotNull(neck) and coordinateNotNull(Tailset) and coordinateNotNull(Tailtip):\n",
        "        angle = getAngle(Tailtip, Tailset, neck)\n",
        "        raised = isRaised(neck, Tailset, Tailtip)\n",
        "        if raised == 1: tailPosition = 180 - angle\n",
        "        elif raised == -1: tailPosition = -1 * (180 - angle)\n",
        "        else: tailPosition = None\n",
        "        if tailPosition is not None and neck == Throat: tailPosition = 18.7 + 0.98*tailPosition\n",
        "        newRow.append(tailPosition)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # head position\n",
        "    if coordinateNotNull(neck) and coordinateNotNull(Nose) \\\n",
        "        and lookingLeft is not None and not frontal \\\n",
        "        and ((coordinateNotNull(L_F_Paw) and coordinateNotNull(L_B_Paw)) or\n",
        "            (coordinateNotNull(R_F_Paw) and coordinateNotNull(R_B_Paw))):\n",
        "\n",
        "        if coordinateNotNull(L_F_Paw) and coordinateNotNull(L_B_Paw): paw1, paw2 = L_F_Paw, L_B_Paw\n",
        "        else: paw1, paw2 = R_F_Paw, R_B_Paw\n",
        "        intersection = getIntersection(paw1, paw2, neck, Nose)\n",
        "        if intersection is None: headPosition = 0\n",
        "        else:\n",
        "            headPosition = getAngle(neck, intersection, paw1)\n",
        "            if not isBefore(neck, intersection, lookingLeft): headPosition = -headPosition\n",
        "            if neck == Throat: headPosition = -2.78 + 0.06*headPosition\n",
        "        newRow.append(headPosition)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # ear position\n",
        "    if coordinateNotNull(Nose) and coordinateNotNull(base_ear) and coordinateNotNull(tip_ear):\n",
        "        earPosition = getAngle(Nose, base_ear, tip_ear)\n",
        "        raised = isRaised(Nose, base_ear, tip_ear)\n",
        "        if raised == 1: earPosition = 180 - earPosition\n",
        "        elif raised == -1: earPosition = -1 * (180 - earPosition)\n",
        "        else: earPosition = None\n",
        "        newRow.append(earPosition)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # mouth condition\n",
        "    if coordinateNotNull(Nose) and coordinateNotNull(base_ear) and coordinateNotNull(Chin):\n",
        "        mouthCondition = getAngle(Nose, base_ear, Chin)\n",
        "        newRow.append(mouthCondition)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # front leg\n",
        "    if lookingLeft:\n",
        "        if coordinateNotNull(L_F_Paw) and coordinateNotNull(L_F_Elbow):\n",
        "            f_paw, f_elbow = L_F_Paw, L_F_Elbow\n",
        "        elif coordinateNotNull(R_F_Paw) and coordinateNotNull(R_F_Elbow):\n",
        "            f_paw, f_elbow = R_F_Paw, R_F_Elbow\n",
        "    else:\n",
        "        if coordinateNotNull(R_F_Paw) and coordinateNotNull(R_F_Elbow):\n",
        "            f_paw, f_elbow = R_F_Paw, R_F_Elbow\n",
        "        elif coordinateNotNull(L_F_Paw) and coordinateNotNull(L_F_Elbow):\n",
        "            f_paw, f_elbow = L_F_Paw, L_F_Elbow\n",
        "\n",
        "    if coordinateNotNull(f_paw) and coordinateNotNull(f_elbow) and coordinateNotNull(neck):\n",
        "        frontLegCondition = getAngle(f_paw, f_elbow, neck)\n",
        "        if neck == Throat: 83.78 + 0.61*frontLegCondition\n",
        "        newRow.append(frontLegCondition)\n",
        "    else: newRow.append(None)\n",
        "\n",
        "    # ___________________________________________________________\n",
        "    # back leg\n",
        "    if lookingLeft:\n",
        "        if coordinateNotNull(L_B_Paw) and coordinateNotNull(L_B_Elbow):\n",
        "            b_paw, b_elbow = L_B_Paw, L_B_Elbow\n",
        "        elif coordinateNotNull(R_B_Paw) and coordinateNotNull(R_B_Elbow):\n",
        "            b_paw, b_elbow = R_B_Paw, R_B_Elbow\n",
        "    else:\n",
        "        if coordinateNotNull(R_B_Paw) and coordinateNotNull(R_B_Elbow):\n",
        "            b_paw = R_B_Paw\n",
        "            b_elbow = R_B_Elbow\n",
        "        elif coordinateNotNull(L_B_Paw) and coordinateNotNull(L_B_Elbow):\n",
        "            b_paw, b_elbow = L_B_Paw, L_B_Elbow\n",
        "\n",
        "    if coordinateNotNull(b_paw) and coordinateNotNull(b_elbow) and coordinateNotNull(Tailset):\n",
        "        backLegCondition = getAngle(b_paw, b_elbow, Tailset)\n",
        "        newRow.append(backLegCondition)\n",
        "    else:\n",
        "        newRow.append(None)\n",
        "\n",
        "    data.append(newRow)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(outputPath, index=False, header=names)"
      ],
      "metadata": {
        "id": "zmmpwmec2pEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification with poses"
      ],
      "metadata": {
        "id": "kTFdADOv36kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Data"
      ],
      "metadata": {
        "id": "fnOspA-0Ukzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('poses.csv')\n",
        "emotion_dirty = df['filepath'].str.split('/')\n",
        "emotion_clean = []\n",
        "for e in emotion_dirty:\n",
        "  filename = e[-1]\n",
        "  emotion = filename.split('_')[0]\n",
        "  emotion_clean.append(emotion)\n",
        "df.insert(loc = 1,\n",
        "                column = 'emotion',\n",
        "                value = emotion_clean)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "u28I0WoA4A90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as split\n",
        "\n",
        "training, test = split(df, test_size = 0.1, random_state = 42)\n",
        "train, validation = split(training, test_size = 0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "ueXnydC7yc3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building multi-input model"
      ],
      "metadata": {
        "id": "Okt8Gib7UnTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50_v01'\n",
        "\n",
        "# load a new instance of the model.\n",
        "base_model = tf.keras.applications.resnet_v2.ResNet50V2(input_shape=(224,224,3),\n",
        "                                              include_top=True,\n",
        "                                              weights='imagenet',\n",
        "                                                    )\n",
        "\n",
        "#model = tf.keras.applications.resnet50.ResNet50(input_shape=(224,224,3),\n",
        " #                                             include_top=True,\n",
        "  #                                            weights='imagenet',\n",
        "   #                                                 )\n",
        "for layer in base_model.layers[-5:]:\n",
        "  print(layer.name)\n",
        "\n",
        "last_conv_layer = base_model.get_layer('conv5_block3_out')\n",
        "\n",
        "conv_model = Model(inputs=base_model.input,\n",
        "                   outputs=last_conv_layer.output)\n",
        "\n",
        "new_model = Sequential()\n",
        "\n",
        "new_model.add(conv_model)\n",
        "\n",
        "new_model.add(Dropout(0.5))\n",
        "\n",
        "new_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "\n",
        "new_model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "conv_model.trainable = True\n",
        "for layer in conv_model.layers:\n",
        " # if(('conv5' not in layer.name) or ('block' not in layer.name) or ('bn' in layer.name)):\n",
        "   if('bn' in layer.name):\n",
        "    layer.trainable = False\n",
        "\n",
        "new_model.summary()"
      ],
      "metadata": {
        "id": "3Ca9OpE7Ui0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Generator"
      ],
      "metadata": {
        "id": "DBf4xfIpZqex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from PIL import Image, ImageEnhance"
      ],
      "metadata": {
        "id": "pcpdY5V7nTA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_df(df, col_name='emotion', n_sample_per_class=140, replace = False):\n",
        "  samples = df.groupby(col_name)\n",
        "  list_cls = df[col_name].unique()\n",
        "  df_lst = []\n",
        "  for cls in list_cls:\n",
        "      cls_df = samples.get_group(cls)\n",
        "      if (cls_df.shape[0] < n_sample_per_class) and (replace==False):\n",
        "        cls_sample = cls_df\n",
        "      else:\n",
        "        cls_sample = cls_df.sample(n=n_sample_per_class,replace=replace,random_state=42)\n",
        "      df_lst.append(cls_sample)\n",
        "  df_sampled = pd.concat(df_lst, sort=False)\n",
        "  df_sampled = shuffle(df_sampled)\n",
        "\n",
        "  return df_sampled"
      ],
      "metadata": {
        "id": "9ha1THnnmy3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoding for emtions\n",
        "emotion_dict = {'Anger': 1,\n",
        "                'Fear ': 2,\n",
        "                'Happiness' : 3,\n",
        "                'Relaxation' : 4}"
      ],
      "metadata": {
        "id": "XX3ej45Zq6QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoodboiGenerator():\n",
        "    \"\"\"\n",
        "   This is a data generator for the Goodboi dataset, adapted from the code used \n",
        "   in this article: \n",
        "   https://towardsdatascience.com/building-a-multi-output-convolutional-neural-network-with-keras-ed24c7bc1178\n",
        "    \"\"\"\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        \n",
        "    def generate_split_indexes(self, random_state= 1313):\n",
        "        p = np.random.RandomState(seed= random_state).permutation(len(self.df))\n",
        "        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n",
        "        train_idx = p[:train_up_to]\n",
        "        test_idx = p[train_up_to:]\n",
        "        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n",
        "        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\n",
        "        \n",
        "        \n",
        "        return train_idx, valid_idx, test_idx\n",
        "\n",
        "\n",
        "\n",
        "#Now to preprocess and generate the images\n",
        "\n",
        "    def preprocess_image(self, img_path, IMG_SIZE = 224, training = False):\n",
        "        \"\"\"\n",
        "        Used to perform some minor preprocessing on the image before inputting \n",
        "        into the network.\n",
        "        \"\"\"\n",
        "        im = tf.keras.preprocessing.image.load_img(img_path)\n",
        "        im = im.resize((IMG_SIZE, IMG_SIZE))\n",
        "        if training == True:\n",
        "          img_contr_obj=ImageEnhance.Contrast(im)\n",
        "          img_sharp_obj=ImageEnhance.Sharpness(im)\n",
        "          factor=2.5\n",
        "          im=img_contr_obj.enhance(factor)\n",
        "          im = img_sharp_obj.enhance(factor)\n",
        "          im = np.array(im).astype(np.float32) / 255.0\n",
        "          im = tf.keras.preprocessing.image.random_brightness(im, \n",
        "                                                              brightness_range=(0.9, 1.1))\n",
        "        else:\n",
        "          im = np.array(im).astype(np.float32) / 255.0\n",
        "        return im\n",
        "        \n",
        "    def generate_images(self,\n",
        "                        image_idx,\n",
        "                        is_training,\n",
        "                        sampling,\n",
        "                        image_aug = False,\n",
        "                        batch_size=16,\n",
        "                        IMG_SIZE = 224):\n",
        "        \"\"\"\n",
        "        Used to generate a batch with images when training/testing/validating \n",
        "        our Keras model.\n",
        "        \"\"\"\n",
        "        \n",
        "        # arrays to store our batched data\n",
        "        images = []\n",
        "        bodyWeights = []\n",
        "        tailPositions = []\n",
        "        headPositions = []\n",
        "        earPositions = []\n",
        "        mouthConditions = []\n",
        "        frontlegs = []\n",
        "        backlegs = []\n",
        "        emotions = []\n",
        "        \n",
        "        #This next section will upsample teh \n",
        "        if sampling:\n",
        "            sample = self.df.iloc[image_idx]\n",
        "            sampled = sample_df(sample, \n",
        "                    'emotion',\n",
        "                    n_sample_per_class= int(sample['emotion'].value_counts().median()),\n",
        "                    replace = True\n",
        "                    )\n",
        "            sampled.reset_index(inplace= True)\n",
        "            image_idx = sampled.index\n",
        "        else:\n",
        "          sampled = self.df.iloc[image_idx]\n",
        "          sampled.reset_index(inplace= True)\n",
        "          image_idx =  sampled.index\n",
        "        while True:\n",
        "          \n",
        "          for idx in image_idx:\n",
        "                slice = sampled.iloc[idx]\n",
        "                \n",
        "                image = slice['filepath']\n",
        "                bodyweight = slice['bodyWeight']\n",
        "                tailposition = slice['tailPosition']\n",
        "                headposition = slice['tailPosition']\n",
        "                earposition = slice['earPosition']\n",
        "                mouthcondition = slice['mouthCondition']\n",
        "                frontleg = slice['frontLeg']\n",
        "                backleg = slice['backLeg']\n",
        "                target = slice['emotion']\n",
        "                emotion = emotion_dict[target]\n",
        "                \n",
        "                im = self.preprocess_image(image,\n",
        "                                           IMG_SIZE = IMG_SIZE,\n",
        "                                           training = image_aug)\n",
        "\n",
        "          # encoding targets\n",
        "                images.append(im)\n",
        "                bodyWeights.append(bodyweight)\n",
        "                tailPositions.append(tailposition)\n",
        "                headPositions.append(headposition)\n",
        "                earPositions.append(earposition)\n",
        "                mouthConditions.append(mouthcondition)\n",
        "                frontlegs.append(frontleg)\n",
        "                backlegs.append(backleg)\n",
        "                emotions.append(emotion)\n",
        "                \n",
        "                # yielding condition\n",
        "                if len(images) >= batch_size:\n",
        "                    #emotions = tf.keras.utils.to_categorical(emotions, 4)\n",
        "                    #yield [np.array(images),[np.array(bodyWeights), np.array(tailPositions), np.array(headPositions), np.array(earPositions), np.array(mouthConditions), np.array(frontlegs), np.array(backlegs)]] , np.array(emotions)\n",
        "                    yield np.array(images) ,  np.array(emotions)\n",
        "                    images = []\n",
        "                    bodyWeights = []\n",
        "                    tailPositions = []\n",
        "                    headPositions = []\n",
        "                    earPositions = []\n",
        "                    mouthConditions = []\n",
        "                    frontlegs = []\n",
        "                    backlegs = []\n",
        "                    emotions = []\n",
        "                    \n",
        "          if not is_training:\n",
        "                break"
      ],
      "metadata": {
        "id": "5vxmGW2RZtM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_TEST_SPLIT = 0.8\n",
        "data_generator = GoodboiGenerator(training)\n",
        "train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()\n",
        "print(len(train_idx), len(valid_idx), len(test_idx))"
      ],
      "metadata": {
        "id": "HfobCxVjiPeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "valid_batch_size = 8\n",
        "train_gen = data_generator.generate_images(train_idx,\n",
        "                                           is_training=True,\n",
        "                                           sampling= True,\n",
        "                                           image_aug= True,\n",
        "                                           batch_size=batch_size,\n",
        "                                           IMG_SIZE = 224)\n",
        "valid_gen = data_generator.generate_images(valid_idx,\n",
        "                                           is_training=True,\n",
        "                                           sampling = False,\n",
        "                                           batch_size=valid_batch_size,\n",
        "                                           IMG_SIZE= 224)"
      ],
      "metadata": {
        "id": "UtGteb0FmuE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_gen)"
      ],
      "metadata": {
        "id": "5HZhfNbXK-Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "playtest = next(train_gen)[0][0]\n",
        "\n",
        "\n",
        "image_to_play = tf.keras.preprocessing.image.array_to_img(playtest)\n",
        "plt.imshow(image_to_play)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GSVgY804mi2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Generator 2"
      ],
      "metadata": {
        "id": "iXjWKQBzS1hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    brightness_range=(.8,1.2),\n",
        "    shear_range=0.005,\n",
        "    zoom_range=[0.9, 1.4],\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode='nearest', cval=0.0,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    dtype=None\n",
        ")\n",
        "\n",
        "image_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    dtype=None\n",
        ")"
      ],
      "metadata": {
        "id": "X9tkghBkS5zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "epochs = 100\n"
      ],
      "metadata": {
        "id": "UogLWErQTICJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = image_gen_train.flow_from_dataframe(dataframe = train,\n",
        "                                               directory = None,\n",
        "                                               x_col = 'filepath',\n",
        "                                               y_col = 'emotion',\n",
        "                                               target_size= (224, 224),\n",
        "                                               batch_size= batch_size,\n",
        "                                               shuffle = True,\n",
        "                                               class_mode = 'sparse')\n",
        "val_gen = image_gen_train.flow_from_dataframe(dataframe = validation,\n",
        "                                               directory = None,\n",
        "                                               x_col = 'filepath',\n",
        "                                               y_col = 'emotion',\n",
        "                                               target_size= (224, 224),\n",
        "                                               batch_size= 2,\n",
        "                                              shuffle = True,\n",
        "                                               class_mode = 'sparse')\n",
        "test_gen = image_gen_val.flow_from_dataframe(dataframe = test,\n",
        "                                              directory = None,\n",
        "                                               x_col = 'filepath',\n",
        "                                               y_col = 'emotion',\n",
        "                                               target_size= (224, 224),\n",
        "                                               batch_size= 1,\n",
        "                                               class_mode = 'sparse')"
      ],
      "metadata": {
        "id": "_Gg2fDVSTKlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen"
      ],
      "metadata": {
        "id": "LSzeV0UFxkBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training"
      ],
      "metadata": {
        "id": "RtFcTtavudBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(class_weight='balanced',\n",
        "                                    classes=np.unique(train_gen.classes),\n",
        "                                    y=train_gen.classes)\n",
        "class_weight\n",
        "class_weight_dict = { i : class_weight[i] for i in range(0, len(class_weight) ) }\n",
        "class_weight_dict"
      ],
      "metadata": {
        "id": "IyG6q1N2ZhRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"models/saved_models/resnet50_v5.h5\", \n",
        "                             monitor='sparse_categorical_accuracy', \n",
        "                             verbose=1, save_best_only=True, \n",
        "                             save_weights_only=True, mode='auto', save_freq= 'epoch')\n",
        "\n",
        "early = EarlyStopping(monitor='sparse_categorical_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=2, min_lr=0.0000000000001)\n",
        "\n",
        "calls = [checkpoint, early, reduce_lr]"
      ],
      "metadata": {
        "id": "1ldCNMTplttO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "wiyt34Rpz743"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "\n",
        "lst_metrics = ['sparse_categorical_accuracy', recall_m, precision_m, f1_m]\n",
        "\n",
        "new_model.compile(optimizer=optimizer, loss=loss, metrics=lst_metrics)"
      ],
      "metadata": {
        "id": "ztCX1N6G0Mq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(train_gen,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch= 70,\n",
        "                    validation_data=val_gen,\n",
        "                    class_weight=class_weight_dict,\n",
        "                    validation_steps = 30,\n",
        "                    callbacks = calls\n",
        "                    ) "
      ],
      "metadata": {
        "id": "a4Q0uGlcl4B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.evaluate(test_gen)"
      ],
      "metadata": {
        "id": "2jr0jih_-Hh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}